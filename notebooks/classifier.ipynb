{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, f1_score \n",
    "from sklearn.metrics import accuracy_score, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.join('../data')\n",
    "VEHICLES = os.path.join(DATA_DIR, 'vehicles')\n",
    "NON_VEHICLES = os.path.join(DATA_DIR, 'non-vehicles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HogFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, color_scheme, orientation, pixels_per_cell, cells_per_block):\n",
    "        self.color_scheme = color_scheme\n",
    "        self.orientation = orientation\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "    \n",
    "    def _hog_feature(self, image):\n",
    "        return hog(image, orientations=self.orientation, \n",
    "                   pixels_per_cell=(self.pixels_per_cell, self.pixels_per_cell), \n",
    "                   cells_per_block=(self.cells_per_block, self.cells_per_block), \n",
    "                   feature_vector=True)\n",
    "    \n",
    "    def fit(self, X, y, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_new = []\n",
    "        for x in X:\n",
    "            img = cv2.cvtColor(x, self.color_scheme).astype(np.float32)/255\n",
    "            # HOG Features\n",
    "            rhf = self._hog_feature(img[:, :, 0])\n",
    "            ghf = self._hog_feature(img[:, :, 1])\n",
    "            bhf = self._hog_feature(img[:, :, 2])\n",
    "            \n",
    "            # Histogram Features\n",
    "            channel1_hist = np.histogram(img[:,:,0], bins=32)\n",
    "            channel2_hist = np.histogram(img[:,:,1], bins=32)\n",
    "            channel3_hist = np.histogram(img[:,:,2], bins=32)\n",
    "            # Concatenate the histograms into a single feature vector\n",
    "            hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "            \n",
    "            X_new.append(np.hstack((rhf, ghf, bhf, hist_features)))\n",
    "        return np.array(X_new)\n",
    "    \n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        return self.fit(X, y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read(data_dir):\n",
    "    for img_path in glob.iglob(os.path.join(data_dir, '*', '*.png')):\n",
    "        image = cv2.imread(img_path)\n",
    "        yield cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vehicles = [feature for feature in read(VEHICLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_vehicles = [feature for feature in read(NON_VEHICLES)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.vstack((vehicles, non_vehicles))\n",
    "labels = np.hstack((np.ones(len(vehicles), np.int32), np.zeros(len(non_vehicles), np.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760, 64, 64, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17760,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14208, 64, 64, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.LinearSVC()\n",
    "scaler = StandardScaler()\n",
    "extractor = HogFeatureExtractor(cv2.COLOR_BGR2YCrCb, 9, 8, 2)\n",
    "pipeline = Pipeline([('hog', extractor), ('scaler', scaler), ('svc', clf)])\n",
    "# pipeline.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_schemes = [cv2.COLOR_BGR2RGB, cv2.COLOR_BGR2HLS, cv2.COLOR_BGR2YCrCb]\n",
    "orientations = [9, 11, 13]\n",
    "ppc = [8, 16]\n",
    "cpb = [2, 3]\n",
    "param_grid = dict(hog__color_scheme=color_schemes,\n",
    "                  hog__orientation=orientations, \n",
    "                  hog__pixels_per_cell=ppc, \n",
    "                  hog__cells_per_block=cpb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pipeline, param_grid=param_grid, \n",
    "                    scoring=make_scorer(f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('grid_cv_hist.p', 'wb') as _file:\n",
    "    pickle.dump(grid, _file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = grid.best_estimator_.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = grid.best_estimator_.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('classifier_hist.p', 'wb') as _file:\n",
    "    pickle.dump(grid.best_estimator_, _file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hog_feature(image, orientations):\n",
    "    return hog(image, orientations=orientations, \n",
    "               pixels_per_cell=(8, 8), \n",
    "               cells_per_block=(2, 2), \n",
    "               feature_vector=True)\n",
    "    \n",
    "def feature_extractor(image, orientations):\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb).astype(np.float32)/255\n",
    "    # HOG Features\n",
    "    rhf = hog_feature(img[:, :, 0], orientations)\n",
    "    ghf = hog_feature(img[:, :, 1], orientations)\n",
    "    bhf = hog_feature(img[:, :, 2], orientations)\n",
    "    return np.hstack((rhf, ghf, bhf))\n",
    "\n",
    "def feature_extractor_w_hist(image, orientations):\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb).astype(np.float32)/255\n",
    "    # HOG Features\n",
    "    rhf = hog_feature(img[:, :, 0], orientations)\n",
    "    ghf = hog_feature(img[:, :, 1], orientations)\n",
    "    bhf = hog_feature(img[:, :, 2], orientations)\n",
    "    # Histogram Features\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=32)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=32)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=32)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    return np.hstack((rhf, ghf, bhf, hist_features))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.990146396396 [[1806   20]\n",
      " [  15 1711]] 0.989875614695\n"
     ]
    }
   ],
   "source": [
    "x_feat1 = [feature_extractor(x, 13) for x in x_train]\n",
    "x_test_feat1 = [feature_extractor(x, 13) for x in x_test]\n",
    "\n",
    "pipe1 = Pipeline([('scaler', StandardScaler()), ('svc', svm.LinearSVC())])\n",
    "pipe1.fit(x_feat1, y_train)\n",
    "\n",
    "pred = pipe1.predict(x_test_feat1)\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "f1 = f1_score(pred, y_test)\n",
    "print(acc, cm, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99268018018 [[1810   15]\n",
      " [  11 1716]] 0.992481203008\n"
     ]
    }
   ],
   "source": [
    "x_feat2 = [feature_extractor_w_hist(x, 13) for x in x_train]\n",
    "x_test_feat2 = [feature_extractor_w_hist(x, 13) for x in x_test]\n",
    "\n",
    "pipe2 = Pipeline([('scaler', StandardScaler()), ('svc', svm.LinearSVC())])\n",
    "pipe2.fit(x_feat2, y_train)\n",
    "\n",
    "pred = pipe2.predict(x_test_feat2)\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "f1 = f1_score(pred, y_test)\n",
    "print(acc, cm, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.989301801802 [[1802   19]\n",
      " [  19 1712]] 0.989023685731\n"
     ]
    }
   ],
   "source": [
    "x_feat3 = [feature_extractor(x, 9) for x in x_train]\n",
    "x_test_feat3 = [feature_extractor(x, 9) for x in x_test]\n",
    "\n",
    "pipe3 = Pipeline([('scaler', StandardScaler()), ('svc', svm.LinearSVC())])\n",
    "pipe3.fit(x_feat3, y_train)\n",
    "\n",
    "pred = pipe3.predict(x_test_feat3)\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "f1 = f1_score(pred, y_test)\n",
    "print(acc, cm, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99268018018 [[1808   13]\n",
      " [  13 1718]] 0.992489890237\n"
     ]
    }
   ],
   "source": [
    "x_feat4 = [feature_extractor_w_hist(x, 9) for x in x_train]\n",
    "x_test_feat4 = [feature_extractor_w_hist(x, 9) for x in x_test]\n",
    "\n",
    "pipe4 = Pipeline([('scaler', StandardScaler()), ('svc', svm.LinearSVC())])\n",
    "pipe4.fit(x_feat4, y_train)\n",
    "\n",
    "pred = pipe4.predict(x_test_feat4)\n",
    "cm = confusion_matrix(pred, y_test)\n",
    "acc = accuracy_score(pred, y_test)\n",
    "f1 = f1_score(pred, y_test)\n",
    "print(acc, cm, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'pipe1': pipe1,\n",
    "    'pipe2': pipe2,\n",
    "    'pipe3': pipe3,\n",
    "    'pipe4': pipe4\n",
    "}\n",
    "\n",
    "with open('classifier.p', 'wb') as _file:\n",
    "    pickle.dump(classifiers, _file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
